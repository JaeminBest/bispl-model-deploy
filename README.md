# Model-Deploy

## Why?

- bispl의 수많은 모델들을 배포하기 어렵다.
- 주된 이유는 모델의 종류가 다양하고, 모델의 형태가 다양하기 때문이다. 각각 inference 코드를 짜는 것이 부담스럽다.
- 일반화된 모델 서빙 방법이 필요하다

## What?

- 총 2개 환경에서 모델을 배포할 수 있는 예시 코드 및 자동화 스크립트를 제공한다
  - 환경 1: Vessl Run (Vessl Workspace를 통한 배포)
  - 환경 2: KServe (On-Prem GPU cluster에서 배포)

## How?

- 예시 코드를 통해 배포하는 방법을 설명한다
- 자동화 스크립트를 통해 배포하는 방법을 설명한다
- 핸즈온을 통해 배포하는 방법을 설명한다
